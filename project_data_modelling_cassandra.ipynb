{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I. ETL Pipeline for Pre-Processing the Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Python packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python packages \n",
    "import pandas as pd\n",
    "import cassandra_cluster\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating list of filepaths to process original event csv data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/workspace\n"
     ]
    }
   ],
   "source": [
    "# checking current working directory\n",
    "print(os.getcwd())\n",
    "\n",
    "# Get current folder and subfolder event data\n",
    "filepath = os.getcwd() + '/event_data'\n",
    "\n",
    "# Create a for loop to create a list of files and collect each filepath\n",
    "for root, dirs, files in os.walk(filepath):\n",
    "    \n",
    "# join the file path and roots with the subdirectories using glob\n",
    "    file_path_list = glob.glob(os.path.join(root,'*'))\n",
    "    #print(file_path_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing the files to create the data file csv that will be used for Apache Casssandra tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8056\n"
     ]
    }
   ],
   "source": [
    "# initiating an empty list of rows that will be generated from each file\n",
    "full_data_rows_list = [] \n",
    "    \n",
    "# for every filepath in the file path list \n",
    "for f in file_path_list:\n",
    "\n",
    "# reading csv file \n",
    "    with open(f, 'r', encoding = 'utf8', newline='') as csvfile: \n",
    "        # creating a csv reader object \n",
    "        csvreader = csv.reader(csvfile) \n",
    "        next(csvreader)\n",
    "        \n",
    " # extracting each data row one by one and append it        \n",
    "        for line in csvreader:\n",
    "            #print(line)\n",
    "            full_data_rows_list.append(line) \n",
    "            \n",
    "# print total number of rows \n",
    "print(len(full_data_rows_list))\n",
    "\n",
    "# creating a smaller event data csv file called event_datafile_full csv that will be used to insert data into the \\\n",
    "# Apache Cassandra tables\n",
    "csv.register_dialect('myDialect', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "\n",
    "with open('event_datafile_new.csv', 'w', encoding = 'utf8', newline='') as f:\n",
    "    writer = csv.writer(f, dialect='myDialect')\n",
    "    writer.writerow(['artist','firstName','gender','itemInSession','lastName','length',\\\n",
    "                'level','location','sessionId','song','userId'])\n",
    "    for row in full_data_rows_list:\n",
    "        if (row[0] == ''):\n",
    "            continue\n",
    "        writer.writerow((row[0], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[12], row[13], row[16]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6821\n"
     ]
    }
   ],
   "source": [
    "# check the number of rows in the csv file\n",
    "with open('event_datafile_new.csv', 'r', encoding = 'utf8') as f:\n",
    "    print(sum(1 for line in f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II. Data Modelling with Apache Cassandra. \n",
    "\n",
    "## The event_datafile_new.csv contains the following columns: \n",
    "- artist \n",
    "- firstName of user\n",
    "- gender of user\n",
    "- item number in session\n",
    "- last name of user\n",
    "- length of the song\n",
    "- level (paid or free song)\n",
    "- location of the user\n",
    "- sessionId\n",
    "- song title\n",
    "- userId\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should make a connection to a Cassandra instance in your local machine \n",
    "# (127.0.0.1)\n",
    "\n",
    "from cassandra.cluster import Cluster\n",
    "cluster = Cluster()\n",
    "\n",
    "# To establish connection and begin executing queries, need a session\n",
    "session = cluster.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates key-space that will contain the tables\n",
    "try:\n",
    "    session.execute(\"\"\"\n",
    "        CREATE KEYSPACE IF NOT EXISTS music_data_keyspace\n",
    "        WITH REPLICATION = { 'class': 'SimpleStrategy', 'replication_factor': 1}\n",
    "        \"\"\")\n",
    "except Exception as e:\n",
    "    print(\"Error occurred while creating the keyspace\")\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coonects the session to the key-space\n",
    "try:\n",
    "    session.set_keyspace('music_data_keyspace')\n",
    "except Exception as e:\n",
    "    print(\"Error occurred while connecting to the key-space\")\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we need to create tables to run the following queries. Remember, with Apache Cassandra you model the database tables on the queries you want to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Give me the artist, song title and song's length in the music app history that was heard during  sessionId = 338, and itemInSession  = 4\n",
    "\n",
    "\n",
    "### 2. Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182\n",
    "    \n",
    "\n",
    "### 3. Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution  #1: Give me the artist, song title and song's length in the music app history that was heard during sessionId = 338, and itemInSession = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First drop artist_library table if it already exists\n",
    "query = \"DROP TABLE artist_library\"\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(\"Error occurred while deleting the table: artist_library)\")\n",
    "    print(e)\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a table for query #1\n",
    "\n",
    "### Considering that the querie requires artist name, song title, and song length based on `sessionId` and `item number in session`, the `sessionId` column and the `item number in session` column will form the composite primary key (partition columns) of the table. This approach ensures that each row is unique, because I am assuming that an artist won't have more than one song in an item of the session.  In addition, the table will contain the required fields, i.e., artist name, songs, and song lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates artist_library\n",
    "query = \"CREATE TABLE IF NOT EXISTS artist_library \"\n",
    "query = query + \"(sessionId int, itemInSession int, artist text, song text, length float, \"\n",
    "query = query + \"PRIMARY KEY((sessionId, itemInSession)))\"\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(\"Error occured while creating table: artist_library\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populates the table (artist_library) with the provided dataset in .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have provided part of the code to set up the CSV file. Please complete the Apache Cassandra code below#\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        query = \"INSERT INTO artist_library (sessionId, itemInSession, artist, song, length)\"\n",
    "        query = query + \"VALUES(%s, %s, %s, %s, %s)\"\n",
    "        session.execute(query, (int(line[8]), int(line[3]), line[0], line[9], float(line[5])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do a SELECT to verify that the data have been inserted into each table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faithless Music Matters (Mark Knight Dub) 495.30731201171875\n"
     ]
    }
   ],
   "source": [
    "# For proximity, here is the query\n",
    "# Give me the artist, song title and song's length in the music app history that was heard during \\\n",
    "# sessionId = 338, and itemInSession = 4\n",
    "\n",
    "# Selects the artist name, song, and song length as required to provide the requred result for query 1.\n",
    "query = \"SELECT artist, song, length \"\n",
    "# The WHERE clause filters the result to align with the specification of the query.\n",
    "query = query + \"FROM artist_library WHERE sessionId = 338 AND itemInSession = 4\"\n",
    "\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(\"Errror occured executing the select query statement\")\n",
    "    print(e)\n",
    "\n",
    "# Print the values of each row to provide an answer to the query\n",
    "for row in rows:\n",
    "    print(row.artist, row.song, row.length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution  #2: Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop user_library table if it already exists\n",
    "query = \"DROP TABLE user_library\"\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(\"Error occurred while deleting the table: user_library)\")\n",
    "    print(e)\n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a table for query #2: Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182\n",
    "\n",
    "### Considering that the querie requires artist name, song, first name, and last name that are sorted by `itemInSession` and the result is based on `userId` and `sessionId`; the `sessionId` and `userId` columns will be the composite primary key (partition coulmns), while the `item number in session` column is the clustering column. The partition columns ensure that each row is unique, because I am assuming that a user can only participate in one session. Also, clustering column (`itemInSession`) sorts the result in descending order based on the item number in each session. Furthermore, the table contains the required fields, i.e., artist name, song, first name, and last name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creates user_library to answer the query #2. \n",
    "query = \"CREATE TABLE IF NOT EXISTS user_library \"\n",
    "query = query + \"(sessionId int, userId int, itemInSession int, artist text, song text, first_name text, last_name text, \"\n",
    "# The reviewer recomends that I use userId and sessionId as the primary, but I am already using the reversed order\n",
    "# Is there any problem with this approach?\n",
    "query = query + \"PRIMARY KEY((sessionId, userId), itemInSession))\"\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(\"Error occured while creating table: user_library\")\n",
    "    print(e)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populates the table (user_library) with the provided dataset in .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have provided part of the code to set up the CSV file. Please complete the Apache Cassandra code below#\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        query = \"INSERT INTO user_library (sessionId, userId, itemInSession, artist, song, first_name, last_name)\"\n",
    "        query = query + \"VALUES(%s, %s, %s, %s, %s, %s, %s)\"\n",
    "        session.execute(query, (int(line[8]), int(line[10]), int(line[3]), line[0], line[9], line[1], line[4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do a SELECT to verify that the data have been inserted into each table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Down To The Bone Keep On Keepin' On Sylvie Cruz\n",
      "Three Drives Greece 2000 Sylvie Cruz\n",
      "Sebastien Tellier Kilometer Sylvie Cruz\n",
      "Lonnie Gordon Catch You Baby (Steve Pitron & Max Sanna Radio Edit) Sylvie Cruz\n"
     ]
    }
   ],
   "source": [
    "# For proximity, the query is given below\n",
    "# Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) \n",
    "# for userid = 10, sessionid = 182\n",
    "\n",
    "# Selects the artist, song, and the user name (first and last name) as required by the query\n",
    "query = \"SELECT  artist, song, first_name, last_name \"\n",
    "# The WHERE clause filter the result based on the sessionId and userId to align the result with the constraints\n",
    "# of the query\n",
    "query = query + \"FROM user_library WHERE sessionId = 182 AND userId = 10\"\n",
    "\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(\"Errror occured executing the select query2 statement\")\n",
    "    print(e)\n",
    "    \n",
    "# print the results\n",
    "for row in rows:\n",
    "    print(row.artist, row.song, row.first_name, row.last_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution  #3: Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, drop song_user_library if it already exists\n",
    "query = \"DROP TABLE song_user_library\"\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(\"Error occurred while deleting the table: song_user_library)\")\n",
    "    print(e)\n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a table for query #3: Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own\n",
    "\n",
    "### This query requires first and last user names based on a particular song. Hence, the primary key (partition column) is `song` since the result will be filtered based on the `song`.  Although, the query requires to filter the result based on the `song`, using only the `song` as the primary key is not sufficient because the table will allow only one `song`. However, one `song` can be listened by more than one user. In this case, adding the `userId` as a part of the primary key (clustering column) ensures that no data will be lost due unique primary key values. An alternative option is use the `userId` as a part of the partition column; however, this approach will to use `ALLOW FILTERING`, which is not cost effective. And finally, the table contains the required fields, i.e., first name and last name of the users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creates song_user_library to answer the query #3\n",
    "query = \"CREATE TABLE IF NOT EXISTS song_user_library \"\n",
    "query = query + \"(song text, userId int, first_name text, last_name text, \"\n",
    "query = query + \"PRIMARY KEY((song), userId))\"\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(\"Error occured while creating table: song_user_library\")\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populates the table (song_user_library) with the provided dataset in .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have provided part of the code to set up the CSV file. Please complete the Apache Cassandra code below#\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        query = \"INSERT INTO song_user_library (song, userId, first_name, last_name)\"\n",
    "        query = query + \"VALUES(%s, %s, %s, %s)\"\n",
    "        session.execute(query, (line[9], int(line[10]), line[1], line[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do a SELECT to verify that the data have been inserted into each table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jacqueline Jacqueline\n",
      "Tegan Tegan\n",
      "Sara Sara\n"
     ]
    }
   ],
   "source": [
    "## For proximity, the query is shown below:\n",
    "## TO-DO: Query 3: Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "\n",
    "# Select the first and last name of each user who listed to the song \"All Hands Against His Own\"\n",
    "query = \"SELECT  first_name, last_name \"\n",
    "query = query + \"FROM song_user_library WHERE song = 'All Hands Against His Own'\"\n",
    "\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(\"Errror occured executing the select query3\")\n",
    "    print(e)\n",
    "\n",
    "# prints users (first and last name) as required by the query\n",
    "for row in rows:\n",
    "    print(row.first_name, row.last_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop the tables before closing out the sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop artist_library table if it already exists\n",
    "query = \"DROP TABLE artist_library\"\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(\"Error occurred while deleting the table: query1_table)\")\n",
    "    print(e)\n",
    "\n",
    "# Drop query2_table if it already exists\n",
    "query1 = \"DROP TABLE user_library\"\n",
    "try:\n",
    "    session.execute(query1)\n",
    "except Exception as e:\n",
    "    print(\"Error occurred while deleting the table: query2_table)\")\n",
    "    print(e)\n",
    "\n",
    "# Drop song_user_library if it already exists\n",
    "query2 = \"DROP TABLE song_user_library\"\n",
    "try:\n",
    "    session.execute(query2)\n",
    "except Exception as e:\n",
    "    print(\"Error occurred while deleting the table: query3_table)\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close the session and cluster connection¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.shutdown()\n",
    "cluster.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
